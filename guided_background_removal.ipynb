{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lwa5xBLElBg"
      },
      "outputs": [],
      "source": [
        "colab = True\n",
        "# install requirements\n",
        "if not colab:\n",
        "    !pip install torch torchvision opencv-python numpy\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install gradio==3.40.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl4kPnv0Oipi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import gradio as gr\n",
        "import torch\n",
        "from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator\n",
        "\n",
        "models = {\n",
        "    \"vit_h\": \"sam_vit_h_4b8939.pth\",\n",
        "    \"vit_l\": \"sam_vit_l_0b3195.pth\",\n",
        "    \"vit_b\": \"sam_vit_b_01ec64.pth\",\n",
        "}\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_model(model_type: str = \"vit_b\" ):\n",
        "    checkpoint = models[model_type]\n",
        "    if not os.path.exists(\"./\"+checkpoint):\n",
        "        import urllib.request\n",
        "        urllib.request.urlretrieve(f\"https://dl.fbaipublicfiles.com/segment_anything/{checkpoint}\", checkpoint)\n",
        "\n",
        "    sam = sam_model_registry[model_type](checkpoint=checkpoint).to(device=DEVICE)\n",
        "    return SamPredictor(sam), SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "predictor, mask_generator = load_model(\"vit_h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxvlH0KgOw3M"
      },
      "source": [
        "# one object one click point\n",
        "\n",
        "upload the input image then you click on the object you want to keep and it automatically generate an output image with only that object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m51zNJoAOtq3"
      },
      "outputs": [],
      "source": [
        "def extract_object(image: np.ndarray, click_x: int, click_y: int):\n",
        "    predictor.set_image(image)\n",
        "    input_point = np.array([[click_x, click_y]])\n",
        "    input_label = np.array([1])\n",
        "    masks, scores, logits = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        multimask_output=True,\n",
        "    )\n",
        "    C, H, W = masks.shape\n",
        "    result_mask = np.zeros((H, W), dtype=bool)\n",
        "    for j in range(C):\n",
        "      result_mask |= masks[j, :, :]\n",
        "\n",
        "    result_mask = result_mask.astype(np.uint8)\n",
        "    # remove background\n",
        "    alpha_channel = np.ones(result_mask.shape, dtype=result_mask.dtype) * 255\n",
        "    alpha_channel[result_mask == 0] = 0\n",
        "    result_image = cv2.merge((image, alpha_channel))\n",
        "    return result_image\n",
        "\n",
        "def extract_object_by_event(image: np.ndarray, evt: gr.SelectData):\n",
        "    click_x, click_y = evt.index\n",
        "\n",
        "    return extract_object(image, click_x, click_y)\n",
        "\n",
        "\n",
        "def get_coords(evt: gr.SelectData):\n",
        "    return evt.index[0], evt.index[1]\n",
        "\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
        "    with gr.Row():\n",
        "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
        "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=600)\n",
        "        output_img = gr.Image(label=\"Output image\", height=600)\n",
        "\n",
        "    input_img.select(get_coords, None, [coord_x, coord_y])\n",
        "    input_img.select(extract_object_by_event, [input_img], output_img)\n",
        "\n",
        "app.launch(inline=False, share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bRQNuxSO2k8"
      },
      "source": [
        "# one object multiple click points\n",
        "\n",
        "The same as before except you can keep clicking on multiple parts of the desired object until you are satisfied.  Each click will add a point to the list selected points. You can Use the \"Clear Points\" button if you want to start over Otherwise you can click on the Segment object button to retrieve the object without the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmtdenOxO27A"
      },
      "outputs": [],
      "source": [
        "def extract_object(image: np.ndarray, points_str: str):\n",
        "    points = eval(points_str)\n",
        "    if not points:\n",
        "        return image\n",
        "\n",
        "    predictor.set_image(image)\n",
        "    input_points = np.array(points)\n",
        "    input_labels = np.array([1] * len(points))\n",
        "    masks, scores, logits = predictor.predict(\n",
        "        point_coords=input_points,\n",
        "        point_labels=input_labels,\n",
        "        multimask_output=True,\n",
        "    )\n",
        "    C, H, W = masks.shape\n",
        "    result_mask = np.zeros((H, W), dtype=bool)\n",
        "    for j in range(C):\n",
        "        result_mask |= masks[j, :, :]\n",
        "\n",
        "    result_mask = result_mask.astype(np.uint8)\n",
        "    alpha_channel = np.ones(result_mask.shape, dtype=result_mask.dtype) * 255\n",
        "    alpha_channel[result_mask == 0] = 0\n",
        "    result_image = cv2.merge((image, alpha_channel))\n",
        "    return result_image\n",
        "\n",
        "def update_points(points, evt: gr.SelectData):\n",
        "    points_list = eval(points)\n",
        "    x, y = evt.index\n",
        "    points_list.append([x, y])\n",
        "    return str(points_list)\n",
        "\n",
        "def clear_points():\n",
        "    return \"[]\"\n",
        "\n",
        "def segment_image(image, points):\n",
        "    if points == \"[]\":\n",
        "        return image, \"No points selected. Please click on the image to add points.\"\n",
        "    result = extract_object(image, points)\n",
        "    return result, f\"Segmentation complete with {len(eval(points))} points.\"\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Multi-Point Object selection\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=500)\n",
        "        output_img = gr.Image(label=\"Output image\", height=500)\n",
        "\n",
        "    points_display = gr.Textbox(label=\"Selected Points\", value=\"[]\")\n",
        "    clear_button = gr.Button(\"Clear Points\")\n",
        "    segment_button = gr.Button(\"Segment Object\")\n",
        "    result_text = gr.Textbox(label=\"Result\")\n",
        "\n",
        "    input_img.select(update_points, points_display, points_display)\n",
        "    clear_button.click(clear_points, None, points_display)\n",
        "    segment_button.click(segment_image, [input_img, points_display], [output_img, result_text])\n",
        "\n",
        "app.launch(inline=False, share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzV7mGWfO3KQ"
      },
      "source": [
        "# Multiple objects multiple clicks\n",
        "\n",
        "This time we generates masks for all potential objects in the image to allow for  multi-object retrieval . Users can select as many objects as they want, and the segmentation will only include the objects they've explicitly selected. \n",
        "\n",
        "Users can click on different objects in the image to select them. Each click adds a point to the \"Selected Points\" list. When \"Segment Objects\" is clicked, the function finds all segments that contain the selected points. The result shows all selected objects segmented, with the background set to transparent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecZGThkqO3dP"
      },
      "outputs": [],
      "source": [
        "def extract_objects(image: np.ndarray, points_str: str):\n",
        "    points = eval(points_str)\n",
        "    if not points:\n",
        "        return image, \"No points selected. Please click on the image to add points.\"\n",
        "\n",
        "    # Generate all possible masks\n",
        "    masks = mask_generator.generate(image)\n",
        "\n",
        "    # Filter masks based on user-provided points\n",
        "    selected_masks = []\n",
        "    for point in points:\n",
        "        x, y = point\n",
        "        for mask in masks:\n",
        "            if mask['segmentation'][y, x]:\n",
        "                selected_masks.append(mask['segmentation'])\n",
        "                break\n",
        "\n",
        "    if not selected_masks:\n",
        "        return image, \"No objects found at the selected points. Try selecting different points.\"\n",
        "\n",
        "    # Combine selected masks\n",
        "    combined_mask = np.zeros(image.shape[:2], dtype=bool)\n",
        "    for mask in selected_masks:\n",
        "        combined_mask |= mask\n",
        "\n",
        "    # Create a new RGBA image\n",
        "    if image.shape[2] == 3:  # If the input is RGB\n",
        "        result_image = np.concatenate([image, np.full((*image.shape[:2], 1), 255, dtype=np.uint8)], axis=-1)\n",
        "    else:  # If the input is already RGBA\n",
        "        result_image = image.copy()\n",
        "\n",
        "    # Apply the combined mask to the image\n",
        "    result_image[~combined_mask] = [0, 0, 0, 0]  # Set background to transparent\n",
        "\n",
        "    return result_image, f\"Segmentation complete. {len(selected_masks)} objects segmented.\"\n",
        "\n",
        "def update_points(points_str, evt: gr.SelectData):\n",
        "    points_list = eval(points_str)\n",
        "    x, y = evt.index\n",
        "    points_list.append([x, y])\n",
        "    return str(points_list)\n",
        "\n",
        "def clear_points():\n",
        "    return \"[]\"\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Interactive Multi-Object background removal\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(label=\"Input image\", height=500)\n",
        "        output_img = gr.Image(label=\"Output image\", height=500)\n",
        "\n",
        "    points_display = gr.Textbox(label=\"Selected Points\", value=\"[]\")\n",
        "    clear_button = gr.Button(\"Clear Points\")\n",
        "    segment_button = gr.Button(\"Segment Objects\")\n",
        "    result_text = gr.Textbox(label=\"Result\")\n",
        "\n",
        "    input_img.select(update_points, points_display, points_display)\n",
        "    clear_button.click(clear_points, None, points_display)\n",
        "    segment_button.click(extract_objects, [input_img, points_display], [output_img, result_text])\n",
        "\n",
        "app.launch(inline=False, share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
